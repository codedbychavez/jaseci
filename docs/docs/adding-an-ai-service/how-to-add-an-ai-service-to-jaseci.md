---
sidebar_position: 2
---

# Adding an AI service to Jaseci

In this example, we are going to create a custom intent classifier to make predictions and expose its classification capabilities to Jaseci.

To maintain portability we will be using Docker. If you would like to learn about docker click [here](https://www.docker.com)

## 1. Generate an AI service scaffolding

To kick things off, we'll need to generate the necessary scaffolding to develop our AI service:

### Before you continue...

Ensure that your terminal is pointing to ai_serving directory in this repo.

### Steps

1. Run:

```
./create_ai_service.sh` [with the AI service name in CamelCase]

```

For example:

```
./create_ai_service.sh XLNet

```

2. Follow the output prompted by the previous step, including:

1) Add steps in the Dockerfile to download and prepare any pre-trained model files. Follow the TODOs.

2) Update requirements.txt with python dependencies required for your model.

3) Fill in the rest of the code in the service code in the flask python file. Follow the TODOs.

4) Take a look at the k8s manifest yaml file. You might need to update the memory limit and/or port.

5) Build the docker image with:

```
docker build -t IMAGE-NAME -f Dockerfile

```

6) Finally, test the service by applying the manifest:

```
kubectl apply -f K8S-YAML

```

## 2. Prepare AI service following Jaseci patterns

The next step is to set up the HTTP service using Jaseci patterns and add support for the desired functionality.

For this we will use:
- [Python](https://www.python.org/)
- [Flask](https://flask.palletsprojects.com/en/2.0.x/)
- [fastText](https://fasttext.cc/)

You can see the example implementation in [ai_serving/fasttext_classifier]. The entry point is `fasttext_classifier.py`.

<!-- TODO: Add contents of entry point here -->

This is setup to:
- Transform the training data in `training_data.json` to the format fastText expects.
- Train and save a model with that data.
- Provide an endpoint to run predictions on the trained model.

#### Docker Container Architecture
- Based on [Python 3.7 image](https://hub.docker.com/_/python)
- Installs fastText module from [GitHub](https://github.com/facebookresearch/fastText#building-fasttext-for-python)
- Installs other requirements from `requirements.txt`
- The `fasttext-classifier-up` script in `fasttext_classifier.yaml` downloads the required code to the container and starts the AI service.

## 3. Configure the YAML file for your AI service

For this step, most of the YAML configuration would have already been generated by the `create_ai_service.sh` script.

In this case it is called `fasttext_classifier.yaml`.

Feel free in inspect the default options and make changes as necessary. See ai_serving/README.md shown earlier for more details.


## 4. Create Jaseci actions for the service

Jaseci actions allows you to add the functionality from an external service to Jaseci itself.
These actions can be used in your Jac code.

This is how we'll be adding support for the fastText classifier service we just setup to Jaseci:

- Add an entry for the new service in `jaseci_core/jaseci/actions/module/ai-serving.config.ini`

```
[FASTTEXT_CLF]
url: http://fasttext-classifier:4675/fasttext-classifier/
```
  - The first mention of `fasttext-classifier` is the container's hostname
  - The second is the endpoint route set up in `fasttext_classifier.py`
  - Notice that the service port (`4675`) that was configured previously in `fasttext_classifier.py` and `fasttext_classifier.yaml` is also used here.
- Create a file with functions for each supported action in `jaseci_core/jaseci/actions/module`
  - Ex: `fasttext_classifier_actions.py`
  - Use `AIServingAPI` to access the service
- Create another file in `jaseci_core/jaseci/actions` to expose those actions
  - Ex: `fasttext_classifier.py`

The `can fasttext_classifier.predict;` action is now available to Jac code.


## 5. Write tests for the created action

To ensure that our newly added functions correctly and continues to function as we make changes, we will add tests to define expected behavior.

Those tests can be added to the `jaseci_core/jaseci/tests` directory.

See the test_fasttext_classifier.py file: `jaseci_core/jaseci/tests/test_fasttext_classifier.py`

Here's what the content of the file looks like:


<!-- TODO: add content for test_fasttext_classifier.py file here -->


## End

Now you're ready to use the `fasttext_classifier` AI service in Jaseci or create your own.